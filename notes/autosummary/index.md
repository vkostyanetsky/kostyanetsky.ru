Записывать все встречи я, судя по моим же [заметкам](/notes/video-recording/), начал ещё в 2020-м. Видео всегда точнее памяти, а ткнуть на «Start Recording» в [OBS](https://obsproject.com) — самый дешёвый способ не потерять какую-нибудь ценную инфу.

Минусы, впрочем, очевидны — с видео нельзя быстро ухватить суть встречи, по нему невозможен быстрый поиск, оно много весит, в нём легко засветить что-то личное и так далее. Чтобы частично компенсировать это, я в течение встреч тезисно помечал ключевые моменты, а потом либо перекидывал в задачник, либо делал себе что-то вроде саммари: с кем встречался, что обсуждали, какие решения подобрали. Если что-то забыл или упустил детали — сверялся с видео.

Однако этот метод тоже не идеален. Создание конспекта (даже тезисного) отъедает фокус от самой встречи. Кроме того, про какие-нибудь забытые по ходу дела подробности можно узнать слишком поздно.

![Забыл](forgot.jpg)

Короче, пришёл к тому, что хороший вариант — просто извлекать из видео аудио разговора, превращать его в текст (нейронкой), а текст разговора — в детальное саммари по встрече (опять нейронка).

Аудио проще всего выдрать через [ffmpeg](https://www.ffmpeg.org) (консольная утилита для работы с аудио и видео). Ниже пример вызова (один аудиоканал, дискретизация 16 кГц + нормализация громкости):

<pre>
ffmpeg.exe -y -i "D:\video.mkv" -vn -ac 1 -ar 16000 -af loudnorm -c:a pcm_s16le "D:\audio.wav"
</pre>

Что до извлечения текста — я экспериментировал с [Vosk](https://alphacephei.com/vosk/) в связке с [recasepunc](https://github.com/benob/recasepunc), но про это без слёз не вспомнить. Даже комментировать не хочу. А вот <s>Боромир</s> [Whisper](https://openai.com/index/whisper) (нейросеть от OpenAI, умеющая распознавать голос) ставится в фоне за 10 минут:

<pre>
py -3.10 -m venv .venv
.\.venv\Scripts\Activate.ps1
pip install setuptools wheel
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118
pip install openai-whisper
</pre>

Пример вызова:

<pre>
whisper "D:\audio.wav" --model medium --language Russian --output_format txt
</pre>

На выходе получится текстовый файл с расшифровкой, который можно запихать в любой чатбот и получить вполне связное саммари. Его, конечно, всё ещё нужно вычитать — убрать ошибки и фантазии, что-то переформулировать — но это всё ещё сильно лучше создания конспекта на ходу.

Вот, в общем-то, и весь метод. Остаётся написать простой скрипт, чтобы не дергать две команды вручную. Если вы тоже на Windows и вам лень вайбкодить свой скрипт, можете [взять мой](https://gist.github.com/vkostyanetsky/4f4760097f1b417cc85d71d11662a642) и подогнать под себя.

Скрипт ищет в своей папке первый попавшийся .mkv, прогоняет через ffmpeg + Whisper и сохраняет результат в ту же папку. Если будете использовать — обратите внимание, что он работает через [CUDA](https://developer.nvidia.com/cuda) (на CPU тоже можно, но будет сильно медленнее) + скачанные модели Whisper он сохраняет не в дефолтный кэш, а в папку с текущим Python-окружением.

(при желании можно прикрутить к нему вызов API или обращение к какой-нибудь модели в локальной [LM Studio](https://lmstudio.ai), но персонально для себя я решил — не, уже перебор)